{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidduran1365/PruebaDeRepo/blob/main/IA_Aplicada_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## License of this notebook\n",
        "\n",
        "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/80x15.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>.\n",
        "\n",
        "### Informaci√≥n\n",
        "\n",
        "> **Author(s)**: <a href=\"https://www.linkedin.com/in/david-duran-r/\">David Duran</a> </br>\n",
        "> **Last updated**: 17/07/2025"
      ],
      "metadata": {
        "id": "7IbQKqjXjqX8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hola"
      ],
      "metadata": {
        "id": "78QhRBldzjS6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introducci√≥n**"
      ],
      "metadata": {
        "id": "0_Mn5iKNp0H2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***¬øQu√© es [huggingface](https://huggingface.co/models)?***\n",
        "\n",
        "\n",
        "\n",
        "*   Es una plataforma que contiene una gran variedad de modelos pre-entrenados para ***Procesamiento de Lenguaje Natural (NLP)*** y ***Visi√≥n por Computadora (CV)*** principalmente. Estos modelos pueden ser compartidos por cualquier usuario.![](https://drive.google.com/uc?export=view&id=1hLzWX9NX3x1OAlEl2EV4Y-BbuJxBbKQi) - - - - **Existen modelos para distintos\n",
        "prop√≥sitos** - - - - ![](https://drive.google.com/uc?export=view&id=1z2dPjHwhYoHseOrA4CPuA0_HsCldJqVo)\n",
        "\n",
        "\n",
        "*   Tambi√©n cuenta con algunos tutoriales/cursos b√°sicos sobre NLP y sobre c√≥mo utilizar los modelos que contiene\n",
        "![](https://drive.google.com/uc?export=view&id=1vwI0rLKt2iNtpIfBNEVdUciX-dQp_jfI)\n",
        "\n"
      ],
      "metadata": {
        "id": "Nvjp8kydqcHV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***¬øQu√© es un modelo pre-entrenado?***\n",
        "\n",
        "Es un modelo de machine learning que fue entrenado utilizando una serie de datos para resolver una o varias tareas. El entrenamiento de estos modelos generalmente se realiza con un conjunto muy grande de datos.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1M8D2NAxSjxjlDMMYTi0baRV4E91dNTtk)\n"
      ],
      "metadata": {
        "id": "qlIWkdJzz2oT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***¬øPor qu√© usar modelos pre-entrenados?***\n",
        "\n",
        "\n",
        "1.   Por la cantidad de datos que se utilizan para entrenarlos\n",
        "2.   Por el tiempo que requieren para ser entrenados\n",
        "3.   Por la contaminaci√≥n que genera un entrenamiento\n",
        "4.   **Porque existe el tranfer learning**\n"
      ],
      "metadata": {
        "id": "vEB3qpmS4V9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Modelos comunes***\n",
        "\n",
        "\n",
        "*   BERT\n",
        "*   RoBERTa\n",
        "*   DistilBERT\n",
        "*   GPT\n",
        "*   LLaMA\n",
        "\n"
      ],
      "metadata": {
        "id": "w7Ob9Nqd6TMu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***¬øQu√© es fine-tuning?***\n",
        "\n",
        "A grandes rasgos, es tomar un modelo pre-entrenado y ajustarlo para un conjunto de datos m√°s espec√≠fico. Aqu√≠ tiene lugar un concepto muy importante, transfer learning, que se refiere a transferir el conocimiento general que tiene el modelo antes del fine-tuning hac√≠a el modelo final mientras que se ajustan un poco los par√°metros para que el nuevo modelo sea mejor en la nueva tarea que se pretende realizar.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1dbBpVgj7fkqsm-5egKOHBtaxHuy-lMEH)\n",
        "\n",
        "Para hacer fine-tuning se necesitan tener datos espec√≠ficos para la tarea que se busca realizar, por ejemplo, si se quiere afinar el modelo para predecir el precio de casas, entonces se debe de contar con una relaci√≥n entre los precios y alguna(s) caracter√≠stica(s) de las casas, como el n√∫mero de habitaciones, medidas, ubicaci√≥n, etc.\n",
        "\n",
        "En principio, no son necesarios un gran n√∫mero de datos para la nueva tarea, pero entre m√°s datos se tengan y estos sean significativos, confiables y est√©n bien etiquetados, mejor ser√° el rendimiento del nuevo modelo en esa tarea.\n",
        "\n",
        "Para afinar apropiadamente un modelo se debe de considerar que exista una cierta similitud entre el mismo y la nueva tarea. Es decir, si se busca realizar un clasificador de sentimientos, debe de utilizarse un modelo que ya realice tareas de clasificaci√≥n, a√∫n si es en otro √°mbito distinto.\n",
        "\n",
        "Se pueden utilizar diferentes modelos pre-entrenados para comparar su rendimiento despu√©s de ser afinados y seleccionar el que cuente con el mejor comportamiento."
      ],
      "metadata": {
        "id": "S4oLkalb-rlW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Datos**"
      ],
      "metadata": {
        "id": "Yca2kqqYGOpi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Etiquetado de datos***\n",
        "\n",
        "Para afinar un modelo se requiere tener datos bien etiquetados y que sean significativos para la tarea que se busca realizar.\n",
        "\n",
        "Supongamos que se quiere predecir el precio de casas, quiz√° solamente contar con una relaci√≥n entre el precio de estas y la medida del terreno no sea suficiente, porque esto no aplicar√≠a para muchas propiedades que son peque√±as pero muy caras y que deben su precio a otros factores como los servicios con los que cuentan, el n√∫mero de habitaciones o la ubicaci√≥n del inmueble.\n",
        "\n",
        "***Preprocesamiento de datos***\n",
        "\n",
        "\n",
        "*   **Limpieza:** Antes de procesar los datos y usarlos para nuestras aplicaciones, debemos asegurarnos de que solo contengan elementos con los que podemos y queremos trabajar. Esto puede implicar eliminar emojis, hashtags, simbolos extra√±os, elementos en otros idiomas, etc.\n",
        "*   **Tokenizaci√≥n:** Los datos que utilizaremos no ser√°n procesados tal cuales por el modelo, es necesario realizar la tokenizaci√≥n de los mismos, que b√°sicamente quiere decir, convertir estos datos a\n",
        "\n"
      ],
      "metadata": {
        "id": "wABJRaUSGfds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Este es un ejemplo de preprocesamiento de un texto\n",
        "! pip install tweet-preprocessor\n",
        "import preprocessor as p\n",
        "p.set_options(p.OPT.EMOJI)\n",
        "original_str='Para comenzar, hago press banco con mancuernas y llegu√© a mi m√°ximo. Levanto 75lbs pero el problema es que no saco m√°s de 4reps, la √∫ltima serie intento sacar la 5 pero es de milagro. No logro pasar de 4 reps las primeras 3 series, solo la √∫ltima hago las 5 y no avanzo üòÖ . Si me pudieran dar consejos en: -¬øComo lograr m√°s repeticiones? -¬øC√≥mo ganar algo m√°s de fuerza? Los leer√© y tratar√© de aplicarlos la pr√≥xima vez'\n",
        "cleaned_str=p.clean(original_str)\n",
        "if original_str!=cleaned_str:\n",
        "  print(\"\",cleaned_str)"
      ],
      "metadata": {
        "id": "Cuiz55yMVvzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Este es un ejemplo de tokenizaci√≥n\n",
        "! pip install transformers\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Crear un tokenizador BERT\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenizar una oraci√≥n\n",
        "input_sentence = \"I like this course\"\n",
        "tokens = tokenizer.tokenize(input_sentence)\n",
        "print(input_sentence)\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "gtY3ApkhYJtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning"
      ],
      "metadata": {
        "id": "wFDjmGB9qPyS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGRuljvlapRp",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Instalaci√≥n de tranformers\n",
        "! pip install transformers\n",
        "! pip install datasets\n",
        "! pip install accelerate -U\n",
        "! pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets huggingface_hub fsspec"
      ],
      "metadata": {
        "id": "6PmJS6PdtwL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos un dataset de rese√±as.\n",
        "#Cada rese√±a cuenta con una calificaci√≥n que va del 0 al 4 y la descripci√≥n de la experiencia\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"Yelp/yelp_review_full\")\n",
        "print(dataset[\"train\"][1])\n",
        "print(dataset[\"train\"][100])\n",
        "print(dataset[\"train\"][200])"
      ],
      "metadata": {
        "id": "OVd-nr4Pa2Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Traemos el tokenizer del modelo que estamos utilizando, que en este caso es \"bert-base-cased\"\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "#Definimos una funci√≥n de tokenizaci√≥n para que esta se realize por partes\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "#Mapear la funci√≥n es m√°s eficiente que aplicarla directamente.\n",
        "#\"batched=True\" indica que enviaremos por partes la informaci√≥n\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "x-mga5YYa2F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Split***\n",
        "Los datos que tenemos deben de ser separados al menos en dos partes (train & test); aunque lo m√°s ideal es separar en tres partes (train, validation & test).\n",
        "\n",
        "\n",
        "*   **train:** son los datos que como tal se utilizar√°n para entrenar el modelo. *Representa la mayor√≠a de los datos.*\n",
        "*   **validation:** se compara el entrenamiento contra datos de validation y si existe overfitting se corrige. *Es una peque√±a parte de los datos, quiz√° un 20-25%*\n",
        "*   **test:** aqu√≠ solo hay datos que el modelo nunca ha visto y que no se utilizan en ning√∫n momento del afinamiento. Nos permiten tener una medida de qu√© tan bueno es el modelo prediciendo. *Es una peque√±a parte de los datos, quiz√° un 15-20%*\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Este es un ejemplo de como separar el dataset en las tres partes correspondientes.** La funci√≥n *train_test_split* solo puede separar en dos conjuntos, por lo que se ocupa dos veces\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, temp_data, train_labels, temp_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "validation_data, test_data, validation_labels, test_labels = train_test_split(temp_data, temp_labels, test_size=0.25, random_state=42)\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "DMuRrB3iZCGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Utilizaremos un n√∫mero limitado de ejemplos del dataset para que el entrenamiento sea m√°s r√°pido,\n",
        "#pues en este caso no nos interesa como tal que el modelo sea bueno en la tarea, sino conocer la\n",
        "#forma en que funciona. Si se quieren mejores resultados pueden aumentarse los items usados\n",
        "#(int√©ntelo con 1000). Por otro lado, si se busca reducir el tiempo pueden utilizarse menos items,\n",
        "#pero obviamente el modelo obtendr√° peores resultados\n",
        "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(10))\n",
        "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(10))"
      ],
      "metadata": {
        "id": "izzn4Phja2Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Aqu√≠ le estamos indicando que se trata de una tarea de clasificaci√≥n\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "#Se vuelve a pasar el nombre del modelo como uno de los par√°metros, adem√°s del n√∫mero de etiquetas\n",
        "#que se tienen, en este caso 5, que corresponden a las calificaciones 0,1,2,3 y 4.\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
      ],
      "metadata": {
        "id": "Q9d6ysNta2A1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos la librer√≠a numpy que se utilizar√° m√°s adelante\n",
        "import numpy as np\n",
        "\n",
        "#En el tutorial de huggingface indica que se utilizar√° el comando \"import evaluate\", pero en realidad\n",
        "#se debe correr primero \"pip install evaluate\", de lo contrario se genera un error\n",
        "! pip install evaluate\n",
        "import evaluate\n",
        "metric = evaluate.load(\"accuracy\")"
      ],
      "metadata": {
        "id": "sSeyDp2qa1-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Esta funci√≥n nos sirve para conocer qu√© tan correctas fueron las predicciones hechas\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "K7S7HHSDa173"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Indicamos que la evaluaci√≥n se realizar√° por √©pocas\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(output_dir=\"PrimerClasificadorSencillo\", evaluation_strategy=\"epoch\")"
      ],
      "metadata": {
        "id": "uJNdHhUda143"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Definimos el modelo con todas las caracter√≠sticas necesarias: qu√© modelo es,\n",
        "#cuales son los argumentos para el entrenamiento, que conjunto de datos de\n",
        "#entrenamiento y evaluaci√≥n utilizaremos y la funci√≥n para las m√©tricas\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=small_train_dataset,\n",
        "    eval_dataset=small_eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "PwXxRXCMa11Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Llamamos a esta funci√≥n para entrenar el modelo como tal\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "WopQOd_ma1v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Guardamos el modelo ya entrenado\n",
        "model.save_pretrained('PrimerClasificadorSencillo')"
      ],
      "metadata": {
        "id": "T118WEGQa1jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Nos logeamos a huggingface utilizando un token de escritura para posteriormente\n",
        "#subir el modelo\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "GmQZwo98bGSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Subimos el nuevo modelo al hub, si se quiere puede ponerse en privado con el argumento\n",
        "#\"private=True\". Tambi√©n es importante subir tanto \"trainer\" como \"tokenizer\" pues sin\n",
        "#tokenizer no habr√° forma de tokenizar los elementos, por lo que no se podr√° usar el modelo\n",
        "trainer.push_to_hub(\"PrimerClasificadorSencillo\")\n",
        "tokenizer.push_to_hub(\"PrimerClasificadorSencillo\")"
      ],
      "metadata": {
        "id": "YODxScsbbGPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Una forma de probar el modelo es importandolo desde huggingface como a cualquier otro,\n",
        "#pues en este punto, ya deber√° encontrarse disponible en la plataforma\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "model=AutoModelForSequenceClassification.from_pretrained(\"katzenbach/PrimerClasificadorSencillo\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"katzenbach/PrimerClasificadorSencillo\")\n",
        "# Para probar el modelo podemos utilizar una o varias oraciones, como se puede ver a continuaci√≥n\n",
        "#Las siguientes dos lineas se utilizar√≠an para probar con una sola oraci√≥n\n",
        "#input_sentence = \"This is a sample sentence for testing.\"\n",
        "#inputs = tokenizer(input_sentence, return_tensors=\"pt\")\n",
        "\n",
        "#Las siguientes lineas se utilizan para probar con varias oraciones\n",
        "raw_inputs = [\n",
        "    \"Loved it! Best experience I've ever had, If I could, I'd eat in that place everyday\",\n",
        "    \"Meal was fine but service was really bad\",\n",
        "    \"Terrible place and awful service. Bad food!\",\n",
        "    \"It's an experience I'm not quite sure I'd repeat again\",\n",
        "]\n",
        "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "print(inputs)"
      ],
      "metadata": {
        "id": "Kmp2iLsvbJDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Los outputs se convierten en n√∫meros que tengan sentido para nuestro etiquetado\n",
        "outputs = model(**inputs)\n",
        "print(outputs.logits)\n",
        "import torch\n",
        "\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "zXaTeX2bbkGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imprimimos las etiquetas del modelo y comparamos contra las predicciones, el campo\n",
        "#con el n√∫mero m√°s alto corresponde a la etiqueta predicha.\n",
        "model.config.id2label"
      ],
      "metadata": {
        "id": "ghSpclmKiIoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QBcTMBbvRbpG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}